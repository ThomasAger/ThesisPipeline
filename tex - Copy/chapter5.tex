\chapter{Investigating Neural Networks In Terms Of Directions}\label{chapter5}

\section{Introduction}

% Neural networks are not interpretable

% But there are a variety of methods for explaining and investigating them

% We contribute to this knowledge in this section by introducing a process to investigate them with directions

% We look at feed-forward networks and auto-encoders. The idea with auto-encoders is that we will be able to map specific terms to more complex ones by reducing the size of the vector space. With feed-forward networks, we want to see how the neural network achieves strong performance on a text classification task, aka how it transforms the representation such that it can achieve strong results on a supervised task.

% The results for auto-encoders was this, feed-forward networks was that

% Summary/whats coming next

\section{Background}

\subsection{Explanations}

% Explanation is a huge field

% The different kinds of explanations

% Where our directions fit-into this paradigm


\subsection{Rules and Neural Networks}

% We plan to use rules in-order to create a kind of mapping of domain knowledge from specific to general using auto-encoders

% There is a history of using rules to understand neural networks, pedagogical etc

% Where our method fits into this


\subsection{Investigation methods}

% There are many visualization/investigation tools

% Where our directions fit-into this paradigm

\subsection{Feed-forward networks}

% Feed-forward networks 

% Basic layout, input/hidden/output, weights

% Activation functions (Relu, Tanh) refer to paper

% Loss (binary_crossentropy), trainer, Adagrad

% Dropout

% Thresholding


\subsection{Auto-encoders}

% Input/output is the same

% Hidden layer constrained in some way so that the representation is more general

% Denoising auto-encoders

% Variations of auto-encoders in recent years. We just use the basic one.

\section{Method}

% Generally, we treat the hidden layers of neural networks as vector spaces.

% We use the same methods as described in chapter 3, obtaining directions and rankings

% Using these directions and rankings, we obtain interpretable representations

\subsection{Auto-encoders}

% Using the interpretable representation, we create a mapping from layer-to-layer using a rule-based classifier

\subsection{Feed-forward networks}

% We simply take the hidden-layer representation and look at what's going on. 

\section{Parameters}

\subsection{Feed-forward Networks}

% We use hyper-parameter optimization to get the best performing neural network

\section{Qualitative Investigation}

\subsection{Feed-forward networks}

\subsection{Auto-encoders}

\section{Conclusion}



 Neural network models that encode spatial relationships in their hidden layers have achieved state-of-the-art in Text Classification by using transfer learning from a pre-trained Language Model \cite{Gong2018}. There have also been neural network models that produce an interpretable representation, for example InfoGan.
 Most state-of-the-art results rely on Vector Space Models. Ideally the method would be able to achieve strong results for simple interpretable classifiers by transforming an existing representation that performs well at the task.
 

\subsection{Chapter 3 Space Types}
\begin{landscape}
	\begin{table}[]
		\begin{tabular}{llllllllll}
			& Genres     &         &         & Keywords  &         &         & Ratings  &         &         \\
			Movies            & D1         & D2      & D3      & D1        & D2      & D3      & D1       & D2      & D3      \\
			Space             & 50 PCA     & 50 MDS  & 100 MDS & 200 PCA   & 200 MDS & 200 MDS & 50 PCA   & 200 PCA & 50 PCA  \\
			Single directions & N/A        & N/A     & N/A     & N/A       & N/A     & N/A     & N/A      & N/A     & N/A     \\
			&            &         &         &           &         &         &          &         &         \\
			& Newsgroups &         &         & Sentiment &         &         & Reuters  &         &         \\
			Rep               & 200 PCA    & 200 PCA & 100 PCA & PCA 100   & PCA 50  & PCA 50  & 200 PCA  & 200 PCA & 100 PCA \\
			Single dir        & 200 MDS    & 100 D2V & 50 D2V  & D2V 100   & PCA 50  & D2V 100 & N/A      & N/A     & N/A     \\
			&            &         &         &           &         &         &          &         &         \\
			& Foursquare &         &         & OpenCYC   &         &         & Geonames &         &         \\
			Placetypes        & D1         & D2      & D3      & D1        & D2      & D3      & D1       & D2      & D3      \\
			Rep               & MDS 100    & AWV 50  & MDS 200 & AWV 50    & MDS 200 & AWV 50  & MDS 50   & MDS 50  & AWV 200 \\
			Single dir        & N/A        & N/A     & N/A     & N/A       & N/A     & N/A     & N/A      & N/A     & N/A    
		\end{tabular}\caption{Space-types, clusters have the same as single directions.}
	\end{table}
\end{landscape}


We trained neural networks with non-linear activation functions so that they would ideally perform better than linear SVM's on the document representations. The assumption behind this is that if the network is able to achieve stronger results on the task than a baseline representation, it must be doing something more than representing the information. In other words, the representation must be better for the task than an unsupervised representation. The goal of this section is to discover why neural networks are able to perform so well, and explain it in terms of directions. 

The  differences between the supervised representation and the unsupervised representation are examined here, with the main question being how exactly does a neural network achieve such strong results on the task? Some general ideas or explanations that are given are that through non-linear transformations, the internal representation of the neural network is able to find a more complex or accurate representation of domain knowledge relevant to the task.  %This elevates neural networks from simply being representation learners to models that can discover and create new ideas in their representations in-order to solve the task.

Theoretically if we are able to identify features from each layer, then we can also map how they interact with each other. 

When obtaining the directions, we set the frequency cut-off to the top 10,000 words and the direction cut-off when classifying to 2000 features. This is arbitrary, as both of these cut-offs need to be tuned for the specific space-type and task in-order to achieve strong results. The reason that these parameters are not tuned in this case is because we are interested in the qualitative nature of the directions, not the performance on the text classification task. 

We investigate the task using the newsgroups as it gives a good example of a representation that contains many different concepts and aspects of domain knowledge, as well as a well defined classification task that if achieved well on clearly demonstrates the representation contains a good amount of information in the domain. The place-types task does not contain too many entities, making it unreliable for neural network training and the reuters task has similar problems. One alternative would be the movies domain, but as identifying the genres of movies is functionally similar to the newsgroups task, we assume that any results found for the newsgroups can easily generalize to any classification task.

To learn the feed-forward networks, we take the highest performing representation found in Table \ref{bg:repsresults} for clusters on depth-3 decision trees and use them as input representations.   For the newsgroups, this is the size 100 Doc2Vec space. Then, we set the hidden-layer to be the same size as the input representation and use a non-linear activation function.  The reasoning behind this is twofold: First, we can assume that the representation that performs well on depth-three decision trees contain good interpretable concepts that can be meaningfully adjusted by the network, and second that this allows for easy comparison between the original representation and the representation taken from the hidden layer of the network. These feedforward networks are simple, but do achieve stronger results than the linear SVM. These act as a "baseline network", by which we can see how fundamentally the most simple neural network representation may work. 

The primary difference between the linear SVM results and the results achieved using this neural network is that the neural network used is multi-label, meaning that all of the classification objectives are trained at the same time. Following results showing that simple neural networks can still perform well on text classification without needing a complex architecture  \cite{Lakhotia2018} \cite{Nam2014}, we use a neural network with the following changes: Cross-entropy loss, Adagrad trainer with default parameters, Dropout, Softmax activation on the output layer, ReLu or tanH activation function. We tune the network for the following values: 

epoch = [100, 200, 300]
activation_function = ["relu", "tanh"]
dropout = [0.1, 0.25, 0.5, 0.75]
hidden_layer_size = [1,  2, 3, 4]


%For each domain, we test two different network set-ups. The first is one where the hidden layer is the same size as the input layer, and the second is where the hidden layer is smaller than the hidden layer. The assumption is that by constraining the hidden layer size, we can force the network to generalize and find more abstract concepts in the hidden-layer, hopefully gaining some insight into the domain by comparing the input representation and the more general hidden representation.

There are no additional techniques applied to improve the performance of the neural networks.
First, directions in the movie domain were examined. When looking at top scoring terms in Section \ref{ch5:topscore}, it was found that NNET-U retained highly separable metadata directions. This seems to indicate that despite directions being uninformative, the neural network will not change the representation enough to make these directions less separable despite adjusting the embedding to better suit the task. In Section \ref{ch5:commonunique} it was found that NNET-U did not contain many unique directions in its top 2,000 scoring terms, but NNET-B did. The directions that were common to all embeddings seemed most relevant to the task. This  gave an explaination for the reason that the disentangled feature representations derived from NNET-U, NNET-B and the unsupervised embedding all performed similarily:  they all contained the directions that are most relevant to the task. 

In \ref{ch5:diffsection} the largest differences in score between directions was examined. It was found that terms relevant to the task had an increased associated NDCG score in the NNET-U representation, and NNET-B had the highest score increases for directions that were not relevant to the task. This gives some explanation for why NNET-B performed worse than NNET-U, NNET-B likely represented terms that were not relevant to the task. In \ref{ch5:cluster-features} it was hypothesized that the reason that this did not result in overall higher performance when using a disentangled feature representation derived from NNET-B is because despite it improving performance when classifying the "Adventure" genre, it sacrificed performance on another genre, namely that a cluster-feature relevant to classifying the "Animation" genre was not present. 

In Section \ref{ch5:newsgroupsquant} cluster-features derived from NNET-B in the newsgroups domain were examined, as they performed as well as NNET-B. It was found that for NNET-B, the features used as the top decision tree nodes seemed to capture abstract concepts more relevant to the task than in the case of NNET-U or the unsupervised embedding. This simply explains the increase in performance.

In Section \ref{ch5:place-typesentities} it was found that entities for features are meaningful in almost all cases, and across all embedding models. This further verifies that features are semantic across domains even when derived from neural network embeddings. It is speculated that using meaningful entities could make the features more understandable. This is further investigated in section \ref{ch5:commonterms}, where it is found that single-term directions common to all embeddings have similar entities across all embeddings. This further validates the idea in section \ref{ch5:commonunique} that each embedding model in the movies domain found similar relevant directions and associated entities that are most relevant to the task, as it shows that common directions are likely common in entity rankings for the domain as well.